from fastapi import FastAPI, UploadFile, File, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse, Response
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import Optional
import uvicorn
from pathlib import Path
import logging
import json
import time

from services.epub_parser import EpubParser
from services.epub_lazy_parser import EpubLazyParser
from services.txt_parser import TxtParser
from services.tts_engine import get_tts_engine
from database import init_db

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="BookRe API",
    description="ç”µå­ä¹¦é˜…è¯»å™¨åç«¯API",
    version="1.0.0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„ç›®å½•å­˜åœ¨ï¼ˆéƒ¨ç½²å‹å¥½ï¼‰
REQUIRED_DIRS = [
    Path("data/audio"),
    Path("data/covers"),
    Path("data/books"),
    Path("temp"),
    Path("logs")
]

for directory in REQUIRED_DIRS:
    directory.mkdir(parents=True, exist_ok=True)
    logger.info(f"âœ… ç›®å½•å·²å°±ç»ª: {directory}")

# æŒ‚è½½éŸ³é¢‘é™æ€æ–‡ä»¶ç›®å½•
app.mount("/audio", StaticFiles(directory="data/audio"), name="audio")
# æŒ‚è½½å°é¢é™æ€æ–‡ä»¶ç›®å½•
COVERS_DIR = Path("data/covers")
app.mount("/covers", StaticFiles(directory="data/covers"), name="covers")

# åˆå§‹åŒ–æ•°æ®åº“
@app.on_event("startup")
async def startup_event():
    logger.info("ğŸš€ å¯åŠ¨BookReåç«¯æœåŠ¡...")
    init_db()
    
    # å¯åŠ¨åå°æ¸…ç†ä»»åŠ¡ (æ¯10åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡ï¼Œä¿ç•™æœ€è¿‘30åˆ†é’Ÿçš„éŸ³é¢‘)
    import asyncio
    async def cleanup_loop():
        while True:
            try:
                await asyncio.sleep(600) # ç­‰å¾…10åˆ†é’Ÿ
                logger.info("ğŸ§¹ æ‰§è¡Œå®šæ—¶æœŸéŸ³é¢‘æ¸…ç†...")
                engine = get_tts_engine()
                # æ¸…ç†è¶…è¿‡ 0.5 å°æ—¶ (30åˆ†é’Ÿ) çš„æ–‡ä»¶
                engine.cleanup_old_audio_files(max_age_hours=0.5)
            except Exception as e:
                logger.error(f"æ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}")
                await asyncio.sleep(60) # å‡ºé”™åçŸ­æš‚åœé¡¿

    asyncio.create_task(cleanup_loop())
    logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ & æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨")

@app.get("/")
async def root():
    return {
        "message": "BookRe APIæœåŠ¡è¿è¡Œä¸­",
        "version": "1.0.0",
        "endpoints": ["/api/books", "/api/parse", "/api/voice"]
    }

@app.post("/api/parse/epub")
async def parse_epub(file: UploadFile = File(...)):
    """è§£æEPUBæ–‡ä»¶"""
    try:
        temp_path = Path(f"temp/{file.filename}")
        temp_path.parent.mkdir(exist_ok=True)
        
        with open(temp_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        parser = EpubParser(str(temp_path))
        result = parser.parse()
        
        temp_path.unlink()
        
        return JSONResponse(content=result)
    
    except Exception as e:
        logger.error(f"EPUBè§£æé”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è§£æå¤±è´¥: {str(e)}")

@app.post("/api/parse/txt")
async def parse_txt(file: UploadFile = File(...)):
    """è§£æTXTæ–‡ä»¶"""
    try:
        content = await file.read()
        
        parser = TxtParser()
        result = parser.parse(content)
        
        return JSONResponse(content=result)
    
    except Exception as e:
        logger.error(f"TXTè§£æé”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è§£æå¤±è´¥: {str(e)}")

# TTS è¯·æ±‚æ¨¡å‹
class TTSRequest(BaseModel):
    text: str
    voice_model: Optional[str] = "zh-CN-XiaoxiaoNeural"
    rate: Optional[str] = "+0%"
    volume: Optional[str] = "+0%"
    stream: Optional[bool] = True
    
    class Config:
        # å…è®¸ä»»æ„ç±»å‹
        arbitrary_types_allowed = True

# ä¹¦ç±å­˜å‚¨ç›¸å…³ç«¯ç‚¹
BOOKS_DATA_DIR = Path("data/books")
BOOKS_DATA_DIR.mkdir(parents=True, exist_ok=True)

# åŸå§‹æ–‡ä»¶å­˜å‚¨ç›®å½• (ç”¨äºæ‡’è§£æ)
UPLOADS_DIR = Path("data/uploads")
UPLOADS_DIR.mkdir(parents=True, exist_ok=True)

# ============ æ‡’è§£æä¸Šä¼ æ¥å£ (ç§’å¼€ä½“éªŒ) ============

def save_book_json(book_id: str, data: dict):
    """ä¿å­˜ä¹¦ç±JSON"""
    file_path = BOOKS_DATA_DIR / f"{book_id}.json"
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_book_json(book_id: str) -> dict:
    """åŠ è½½ä¹¦ç±JSON"""
    file_path = BOOKS_DATA_DIR / f"{book_id}.json"
    if not file_path.exists():
        return None
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)

async def process_chapters_background(book_id: str):
    """åå°ä»»åŠ¡ï¼šé€ç« è§£æå†…å®¹"""
    try:
        book_data = load_book_json(book_id)
        if not book_data:
            return
        
        file_path = book_data.get('originalFilePath')
        if not file_path or not Path(file_path).exists():
            return
        
        logger.info(f"ğŸ“– åå°è§£æå¼€å§‹: {book_data.get('title')}")
        parser = EpubLazyParser(file_path)
        
        for i, chapter in enumerate(book_data.get('chapters', [])):
            if chapter.get('content') is None:
                parsed = parser.parse_single_chapter(i)
                if parsed:
                    book_data['chapters'][i] = parsed
                    # æ¯è§£æ5ç« ä¿å­˜ä¸€æ¬¡
                    if i % 5 == 0:
                        save_book_json(book_id, book_data)
        
        book_data['parsing_status'] = 'completed'
        save_book_json(book_id, book_data)
        logger.info(f"âœ… åå°è§£æå®Œæˆ: {book_data.get('title')}")
        
    except Exception as e:
        logger.error(f"âŒ åå°è§£æå¤±è´¥: {e}")

@app.post("/api/books/upload")
async def upload_book_lazy(
    file: UploadFile = File(...)
):
    """
    ä¸Šä¼ ä¹¦ç± - æé€Ÿæ‡’è§£ææ¨¡å¼
    - åˆ†å—å†™å…¥å¤§æ–‡ä»¶ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
    - åªè§£æå…ƒæ•°æ®ï¼Œç»ä¸è¯»å–æ­£æ–‡
    - ç§’çº§è¿”å›
    """
    book_id = str(int(time.time() * 1000))
    file_ext = file.filename.split('.')[-1].lower()
    
    if file_ext not in ['epub', 'txt']:
        raise HTTPException(400, f"ä¸æ”¯æŒçš„æ ¼å¼: {file_ext}")
    
    try:
        # 1. åˆ†å—å†™å…¥æ–‡ä»¶ï¼Œé˜²æ­¢24MBæ–‡ä»¶å¯¼è‡´å†…å­˜æº¢å‡º
        original_path = UPLOADS_DIR / f"{book_id}.{file_ext}"
        total_size = 0
        
        with open(original_path, "wb") as f:
            while chunk := await file.read(1024 * 1024):  # 1MB chunks
                f.write(chunk)
                total_size += len(chunk)
        
        logger.info(f"ğŸ“¤ æ–‡ä»¶å·²ä¿å­˜: {original_path} ({total_size/1024/1024:.2f}MB)")
        
        # 2. æé€Ÿè§£æå…ƒæ•°æ® (ä½¿ç”¨æ–°çš„ zipfile è§£æå™¨ï¼Œä¸è¯»å–æ­£æ–‡)
        if file_ext == 'epub':
            parser = EpubLazyParser(str(original_path))
            metadata = parser.parse_metadata_only()
        else:
            # TXTï¼šç®€å•è¯»å–å‰1000å­—ç¬¦ä½œä¸ºé¢„è§ˆ
            with open(original_path, 'r', encoding='utf-8', errors='ignore') as f:
                preview = f.read(1000)
            
            # ç®€å•åˆ†ç« 
            from services.txt_parser import TxtParser
            txt_parser = TxtParser()
            # æ³¨æ„ï¼šTXTä¹Ÿåº”è¯¥æ‡’åŠ è½½ï¼Œè¿™é‡Œå…ˆç®€åŒ–å¤„ç†
            with open(original_path, 'rb') as f:
                content = f.read()
            metadata = txt_parser.parse(content)
        
        # 3. æ„å»ºç²¾ç®€çš„ä¹¦ç±æ•°æ® (chapters.content ç»å¯¹ä¸º None)
        chapters_meta = []
        for ch in metadata.get('chapters', []):
            chapters_meta.append({
                'index': ch.get('index', 0),
                'id': ch.get('id', ''),
                'title': ch.get('title', f'ç« èŠ‚'),
                'href': ch.get('href', ''),
                'content': None,  # !! å…³é”®ï¼šç»å¯¹ä¸º Noneï¼Œä¸å ç©ºé—´
                'word_count': 0
            })
        
        book_data = {
            'id': book_id,
            'title': metadata.get('title', file.filename),
            'author': metadata.get('author', 'æœªçŸ¥ä½œè€…'),
            'cover': metadata.get('cover'),  # å°é¢å¯èƒ½è¾ƒå¤§ï¼Œä½†å·²é™åˆ¶500KB
            'format': file_ext,
            'chapters': chapters_meta,  # åªæœ‰ç›®å½•ï¼Œæ— å†…å®¹
            'totalPages': len(chapters_meta),
            'progress': 0,
            'currentPage': 0,
            'currentChapter': 0,
            'createdAt': __import__('datetime').datetime.now().isoformat(),
            'lastReadAt': __import__('datetime').datetime.now().isoformat(),
            'originalFilePath': str(original_path),
            'parsing_status': 'lazy'  # æ ‡è®°ä¸ºæ‡’åŠ è½½æ¨¡å¼
        }
        
        # 4. ä¿å­˜ç²¾ç®€JSON (åº”è¯¥åªæœ‰å‡ KB)
        save_book_json(book_id, book_data)
        
        # è®¡ç®—JSONå¤§å°
        json_path = BOOKS_DATA_DIR / f"{book_id}.json"
        json_size = json_path.stat().st_size
        logger.info(f"âœ… ä¹¦ç±å·²åˆ›å»º: {book_data['title']} (ID: {book_id}, JSON: {json_size/1024:.1f}KB)")
        
        # 5. ä¸å¯åŠ¨åå°ä»»åŠ¡ï¼ç”¨æˆ·ç¿»é¡µæ—¶æŒ‰éœ€åŠ è½½
        
        return {
            "book_id": book_id,
            "title": book_data['title'],
            "author": book_data['author'],
            "cover": book_data['cover'],
            "total_chapters": len(chapters_meta)
        }
        
    except Exception as e:
        logger.error(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(500, f"ä¸Šä¼ å¤±è´¥: {str(e)}")

@app.get("/api/books/{book_id}/chapter/{index}")
async def get_chapter_content(book_id: str, index: int):
    """
    è·å–ç« èŠ‚å†…å®¹ - æŒ‰éœ€è§£æ
    å¦‚æœåå°è¿˜æ²¡è§£æåˆ°ï¼Œå®æ—¶è§£æè¯¥ç« èŠ‚
    """
    book_data = load_book_json(book_id)
    if not book_data:
        raise HTTPException(404, "ä¹¦ç±ä¸å­˜åœ¨")
    
    chapters = book_data.get('chapters', [])
    if index < 0 or index >= len(chapters):
        raise HTTPException(404, "ç« èŠ‚ä¸å­˜åœ¨")
    
    chapter = chapters[index]
    
    # å¦‚æœå†…å®¹ä¸ºç©ºï¼Œå®æ—¶è§£æ
    if chapter.get('content') is None:
        file_path = book_data.get('originalFilePath')
        if file_path and Path(file_path).exists():
            parser = EpubLazyParser(file_path)
            parsed = parser.parse_single_chapter(index)
            
            if parsed:
                # æ›´æ–°ç¼“å­˜
                book_data['chapters'][index] = parsed
                save_book_json(book_id, book_data)
                return parsed
        
        # è§£æå¤±è´¥è¿”å›ç©ºç« èŠ‚
        return {
            'index': index,
            'title': chapter.get('title', f'ç¬¬ {index + 1} ç« '),
            'content': 'ç« èŠ‚å†…å®¹åŠ è½½å¤±è´¥',
            'word_count': 0
        }
    
    return chapter

@app.get("/api/books")
async def list_books(deviceId: Optional[str] = None):
    """åˆ—å‡ºæ‰€æœ‰ä¹¦ç± (ä»…å…ƒæ•°æ®)"""
    try:
        import json
        books = []
        for file_path in BOOKS_DATA_DIR.glob("*.json"):
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    
                    # æ„å»ºè¿”å›æ•°æ®
                    book_meta = {
                        'id': data.get('id'),
                        'title': data.get('title'),
                        'author': data.get('author'),
                        'cover': data.get('cover'),
                        'format': data.get('format'),
                        'totalPages': data.get('totalPages'),
                        'createdAt': data.get('createdAt'),
                        'filePath': data.get('filePath')
                    }
                    
                    # å¦‚æœæä¾›äº† deviceIdï¼Œè¿”å›è¯¥è®¾å¤‡çš„è¿›åº¦
                    if deviceId and 'devices' in data:
                        device_data = data['devices'].get(deviceId, {})
                        book_meta.update({
                            'progress': device_data.get('progress', 0),
                            'currentPage': device_data.get('currentPage', 0),
                            'currentChapter': device_data.get('currentChapter', 0),
                            'lastReadAt': device_data.get('lastReadAt', data.get('createdAt'))
                        })
                    else:
                        # å…¼å®¹æ—§æ•°æ®æˆ–æ— è®¾å¤‡IDçš„æƒ…å†µ
                        book_meta.update({
                            'progress': data.get('progress', 0),
                            'currentPage': data.get('currentPage', 0),
                            'currentChapter': data.get('currentChapter', 0),
                            'lastReadAt': data.get('lastReadAt', data.get('createdAt'))
                        })
                    
                    books.append(book_meta)
            except Exception as e:
                logger.warning(f"è¯»å–ä¹¦ç±æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # æŒ‰æ—¶é—´å€’åºæ’åº
        books.sort(key=lambda x: x.get("lastReadAt", x.get("createdAt", "")), reverse=True)
        return books
    except Exception as e:
        logger.error(f"è·å–ä¹¦ç±åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/books/save")
async def save_book(request: Request):
    """ä¿å­˜ä¹¦ç±æ•°æ®åˆ°åç«¯æ–‡ä»¶"""
    try:
        import json
        data = await request.json()
        book_id = data.get("id")
        if not book_id:
            raise HTTPException(status_code=400, detail="Missing book ID")
        
        file_path = BOOKS_DATA_DIR / f"{book_id}.json"
        
        # å¤„ç†å°é¢å›¾ç‰‡ (Base64 -> File)
        cover_data = data.get("cover")
        if cover_data and cover_data.startswith("data:image"):
            try:
                import base64
                # æå– base64 æ•°æ®
                header, encoded = cover_data.split(",", 1)
                file_ext = "jpg"
                if "png" in header:
                    file_ext = "png"
                
                # ä¿å­˜ä¸ºæ–‡ä»¶
                cover_filename = f"{book_id}.{file_ext}"
                cover_path = COVERS_DIR / cover_filename
                
                with open(cover_path, "wb") as f:
                    f.write(base64.b64decode(encoded))
                
                # æ›´æ–°æ•°æ®ä¸­çš„ cover å­—æ®µä¸º URL
                data["cover"] = f"/covers/{cover_filename}"
                logger.info(f"å°é¢å·²è½¬å­˜: {cover_filename}")
            except Exception as e:
                logger.error(f"å°é¢è½¬å­˜å¤±è´¥: {e}")
                # å¤±è´¥æ—¶ä¿ç•™åŸ Base64ï¼Œé¿å…æ•°æ®ä¸¢å¤±

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        logger.info(f"ä¹¦ç±å·²ä¿å­˜: {book_id}")
        return {"status": "success", "message": "Book saved", "cover": data.get("cover")}
    except Exception as e:
        logger.error(f"ä¿å­˜ä¹¦ç±å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/books/{book_id}")
async def load_book(book_id: str, deviceId: str = None):
    """åŠ è½½ä¹¦ç±æ•°æ® (æ”¯æŒå¤šè®¾å¤‡è¿›åº¦åŒæ­¥)"""
    try:
        import json
        file_path = BOOKS_DATA_DIR / f"{book_id}.json"
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="Book not found")
            
        with open(file_path, "r", encoding="utf-8") as f:
            book_data = json.load(f)
            
        # å¦‚æœæä¾›äº† deviceIdï¼Œè¯»å–è¯¥è®¾å¤‡çš„è¿›åº¦è¦†ç›–é»˜è®¤è¿›åº¦
        if deviceId and "devices" in book_data and deviceId in book_data["devices"]:
            device_progress = book_data["devices"][deviceId]
            # ä»…è¦†ç›–è¿›åº¦ç›¸å…³å­—æ®µï¼Œä¿ç•™ä¹¦ç±å…ƒæ•°æ®
            book_data["progress"] = device_progress.get("progress", 0)
            book_data["currentPage"] = device_progress.get("currentPage", 0)
            book_data["currentChapter"] = device_progress.get("currentChapter", 0)
            book_data["lastReadAt"] = device_progress.get("lastReadAt")
            logger.info(f"å·²åŠ è½½è®¾å¤‡è¿›åº¦: {deviceId} -> {book_data['currentPage']}é¡µ")
            
        return book_data
    except Exception as e:
        logger.error(f"åŠ è½½ä¹¦ç±å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/books/{book_id}")
async def delete_book(book_id: str):
    """åˆ é™¤ä¹¦ç±æ–‡ä»¶"""
    try:
        file_path = BOOKS_DATA_DIR / f"{book_id}.json"
        if file_path.exists():
            file_path.unlink()
            logger.info(f"ä¹¦ç±å·²åˆ é™¤: {book_id}")
            
        return {"status": "success", "message": "Book deleted"}
    except Exception as e:
        logger.error(f"åˆ é™¤ä¹¦ç±å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.patch("/api/books/{book_id}")
async def update_book_metadata(book_id: str, request: Request):
    """æ›´æ–°ä¹¦ç±å…ƒæ•°æ® (æ”¯æŒå¤šè®¾å¤‡åŒæ­¥)"""
    import traceback
    
    try:
        import json
        updates = await request.json()
        device_id = updates.pop('deviceId', None)
        
        logger.info(f"ğŸ“ è¿›åº¦æ›´æ–°è¯·æ±‚: book={book_id}, device={device_id}, data={updates}")
        
        file_path = BOOKS_DATA_DIR / f"{book_id}.json"
        if not file_path.exists():
            logger.warning(f"âš ï¸ ä¹¦ç±ä¸å­˜åœ¨: {book_id}")
            raise HTTPException(status_code=404, detail="Book not found")
            
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        if device_id:
            # å¤šè®¾å¤‡æ¨¡å¼ï¼šæ›´æ–°ç‰¹å®šè®¾å¤‡çš„è¿›åº¦
            if 'devices' not in data:
                data['devices'] = {}
            
            if device_id not in data['devices']:
                data['devices'][device_id] = {}
            
            # åªæ›´æ–°è¿›åº¦ç›¸å…³å­—æ®µ
            progress_fields = ['progress', 'currentPage', 'currentChapter', 'lastReadAt']
            for field in progress_fields:
                if field in updates:
                    data['devices'][device_id][field] = updates[field]
            
            logger.info(f"âœ… è®¾å¤‡ {device_id} è¿›åº¦å·²æ›´æ–°: page={updates.get('currentPage')}")
        else:
            # å…¼å®¹æ—§ç‰ˆï¼šç›´æ¥æ›´æ–°æ ¹å­—æ®µ
            if 'chapters' in updates:
                del updates['chapters']
            data.update(updates)
        
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… è¿›åº¦ä¿å­˜æˆåŠŸ: {book_id}")
        return {
            "status": "success", 
            "message": "Metadata updated",
            "savedTo": "cloud"  # æ˜ç¡®è¿”å›ä¿å­˜ä½ç½®
        }
        
    except HTTPException:
        raise
    except json.JSONDecodeError as e:
        logger.error(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„JSONæ•°æ®: {str(e)}")
    except PermissionError as e:
        logger.error(f"âŒ æ–‡ä»¶æƒé™é”™è¯¯: {str(e)}\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨æ–‡ä»¶æƒé™é”™è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°ä¹¦ç±å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/books/{book_id}/cover")
async def upload_cover(book_id: str, file: UploadFile = File(...)):
    """æ‰‹åŠ¨ä¸Šä¼ å°é¢"""
    try:
        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not file.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="åªå…è®¸ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶")
            
        file_ext = file.filename.split(".")[-1].lower()
        if file_ext not in ["jpg", "jpeg", "png", "webp"]:
            file_ext = "jpg" # é»˜è®¤
            
        cover_filename = f"{book_id}.{file_ext}"
        cover_path = COVERS_DIR / cover_filename
        
        # ä¿å­˜æ–‡ä»¶
        with open(cover_path, "wb") as f:
            content = await file.read()
            f.write(content)
            
        # æ›´æ–°ä¹¦ç± JSON
        import json
        json_path = BOOKS_DATA_DIR / f"{book_id}.json"
        if json_path.exists():
            with open(json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            data["cover"] = f"/covers/{cover_filename}"
            
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        
        return {"status": "success", "url": f"/covers/{cover_filename}"}
        
    except Exception as e:
        logger.error(f"ä¸Šä¼ å°é¢å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/books/{book_id}/cover/auto")
async def auto_match_cover(book_id: str):
    """è‡ªåŠ¨åŒ¹é…ç½‘ç»œå°é¢"""
    try:
        import json
        from services.cover_search import search_cover_online, download_image
        
        # è¯»å–ä¹¦ç±ä¿¡æ¯
        file_path = BOOKS_DATA_DIR / f"{book_id}.json"
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="Book not found")
            
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            
        title = data.get("title", "")
        author = data.get("author", "")
        
        # æœç´¢å°é¢ URL
        cover_url = await search_cover_online(title, author)
        if not cover_url:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°åŒ¹é…çš„å°é¢")
            
        # ä¸‹è½½å›¾ç‰‡
        image_data = await download_image(cover_url)
        if not image_data:
            raise HTTPException(status_code=500, detail="å°é¢ä¸‹è½½å¤±è´¥")
            
        # ä¿å­˜æ–‡ä»¶
        cover_filename = f"{book_id}.jpg"
        cover_path = COVERS_DIR / cover_filename
        
        with open(cover_path, "wb") as f:
            f.write(image_data)
            
        # æ›´æ–° JSON
        data["cover"] = f"/covers/{cover_filename}"
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        return {"status": "success", "url": data["cover"], "source": cover_url}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è‡ªåŠ¨åŒ¹é…å°é¢å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# TTSç›¸å…³ç«¯ç‚¹
@app.get("/api/voice/list")
async def list_voices():
    """è·å–å¯ç”¨çš„è¯­éŸ³åˆ—è¡¨"""
    try:
        engine = get_tts_engine()
        return engine.get_available_voices()
    except Exception as e:
        logger.error(f"è·å–è¯­éŸ³åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/voice/synthesize")
async def synthesize_voice(request: Request):
    """
    è¯­éŸ³åˆæˆæ¥å£ - ä½¿ç”¨åŸå§‹ Request å¯¹è±¡ç»•è¿‡ Pydantic
    """
    try:
        # æ‰‹åŠ¨è§£æ JSON è¯·æ±‚ä½“
        body = await request.body()
        logger.info(f"===== æ”¶åˆ°åŸå§‹è¯·æ±‚ä½“ =====")
        logger.info(f"Body length: {len(body)} bytes")
        logger.info(f"Body (first 500 chars): {body[:500]}")
        
        # è§£æ JSON
        import json
        data = json.loads(body)
        logger.info(f"è§£æåçš„ JSON: {data}")
        
        # æå–å‚æ•°
        text = data.get("text", "")
        voice_model = data.get("voice_model", "zh-CN-XiaoxiaoNeural")
        rate = data.get("rate", "+0%")
        volume = data.get("volume", "+0%")
        stream = data.get("stream", True)
        
        logger.info(f"===== æå–çš„å‚æ•° =====")
        logger.info(f"text é•¿åº¦: {len(text)}")
        logger.info(f"text é¢„è§ˆ: {text[:100]}")
        logger.info(f"voice_model: {voice_model}")
        logger.info(f"rate: {rate}")
        logger.info(f"stream: {stream}")
        
        if not text:
            raise HTTPException(status_code=400, detail="æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        
        logger.info(f"å¼€å§‹ TTS åˆæˆ...")
        
        engine = get_tts_engine()
        
        if stream:
            logger.info("ä½¿ç”¨æµå¼åˆæˆ")
            return StreamingResponse(
                engine.stream_synthesize(text, voice_model, rate, volume),
                media_type="audio/mpeg"
            )
        else:
            logger.info("ä½¿ç”¨æ–‡ä»¶åˆæˆ")
            output_path = await engine.synthesize(text, voice_model, rate, volume)
            return {"audio_url": f"/audio/{output_path.name}"}
            
    except json.JSONDecodeError as e:
        logger.error(f"JSON è§£æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„ JSON: {str(e)}")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "service": "bookre-api"}

if __name__ == "__main__":
    uvicorn.run(
        "app:app",
        host="127.0.0.1",
        port=8000,
        reload=True,
        log_level="info"
    )
